{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_undirected, degree\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Wiki Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_PATH = \"../data/raw/WIKI\"\n",
    "OUT_PATH = \"../data/processed/WIKI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WIKIGraphProcessor:\n",
    "    def __init__(self, in_dir: str, out_dir: str) -> None:\n",
    "        self.in_dir = in_dir\n",
    "        self.out_dir = out_dir\n",
    "\n",
    "    def _load_quadruples(self, file_name: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Given a filename from the in_dir, load the quadruples and times.\n",
    "        Returns Quadruples (head, relation, tail, time) and times.\n",
    "\n",
    "        Returns:\n",
    "            quadruples: np.ndarray\n",
    "            times: np.ndarray\n",
    "\n",
    "        \"\"\"\n",
    "        # Extract\n",
    "        file_path = os.path.join(self.in_dir, file_name)\n",
    "        textfile = open(file_path, \"r\")\n",
    "        lines = textfile.readlines()\n",
    "\n",
    "        # Transform\n",
    "        quadruples = []\n",
    "        timestamps = set()\n",
    "        for line in lines:\n",
    "            quadruple_str = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "            quadruple_int = [int(i) for i in quadruple_str]\n",
    "\n",
    "            quadruples.append(quadruple_int)\n",
    "            timestamps.add(quadruple_int[3])\n",
    "\n",
    "        return np.array(quadruples), np.asarray(sorted(list(timestamps)))\n",
    "\n",
    "    def _get_network_stats(self):\n",
    "        \"\"\"\n",
    "        Get the total number of nodes and edges in the graph.\n",
    "\n",
    "        Returns:\n",
    "            num_nodes: int\n",
    "            num_edges: int\n",
    "        \"\"\"\n",
    "        STAT_FILENAME = \"stat.txt\"\n",
    "\n",
    "        textfile = open(os.path.join(self.in_dir, STAT_FILENAME), \"r\")\n",
    "        lines = textfile.readlines()\n",
    "\n",
    "        n_nodes, n_edges, _ = lines[0].replace(\"\\n\", \"\").split(\"\\t\")\n",
    "        return int(n_nodes), int(n_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n# Initialize the processor\\nprocessor = WIKIGraphProcessor(IN_PATH, OUT_PATH)\\n\\n# Load data\\nquadruples, times = processor._load_quadruples(\"train.txt\")\\nn_entites, n_relations = processor._get_network_stats() \\n\\n'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "# Initialize the processor\n",
    "processor = WIKIGraphProcessor(IN_PATH, OUT_PATH)\n",
    "\n",
    "# Load data\n",
    "quadruples, times = processor._load_quadruples(\"train.txt\")\n",
    "n_entites, n_relations = processor._get_network_stats() \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Quadruple:\n",
    "    source_id: int\n",
    "    relation_id: int\n",
    "    object_id: int\n",
    "    timestamp: int\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_quadruples(self, file_name: str) -> Tuple[List[Quadruple], List[int]]:\n",
    "        quadruples = []\n",
    "        times = set()\n",
    "\n",
    "        textfile = open(file_name, \"r\")\n",
    "        lines = textfile.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            source_id, relation_id, object_id, timestamp, _ = map(\n",
    "                int, line.strip().split()\n",
    "            )\n",
    "            quadruples.append(Quadruple(source_id, relation_id, object_id, timestamp))\n",
    "            times.add(timestamp)\n",
    "        return quadruples, times\n",
    "\n",
    "    def get_total_number(self, file_name: str) -> Tuple[int, int]:\n",
    "        textfile = open(file_name, \"r\")\n",
    "        num_entities, num_relations, _ = map(int, textfile.readline().strip().split())\n",
    "        return num_entities, num_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphGenerator:\n",
    "    def __init__(self, num_entities: int, num_relations: int):\n",
    "        self.num_entities = num_entities\n",
    "        self.num_relations = num_relations\n",
    "\n",
    "    def get_data_for_time_step(\n",
    "        self, quadruples: List[Quadruple], time_step: int\n",
    "    ) -> List[Quadruple]:\n",
    "        \"\"\"\n",
    "        Given a list of quadruples and a time step, return the quadruples at that time step.\n",
    "        \"\"\"\n",
    "        return [q for q in quadruples if q.timestamp == time_step]\n",
    "\n",
    "    def generate_graph(self, data: List[Quadruple]) -> Data:\n",
    "        \"\"\"\n",
    "        Generate Graph from the quadruples.\n",
    "        \"\"\"\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for quadruple in data:\n",
    "            edge_index.append([quadruple.source_id, quadruple.object_id])\n",
    "            edge_attr.append(quadruple.relation_id)\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "        data = Data(\n",
    "            edge_index=edge_index, edge_attr=edge_attr, num_nodes=self.num_entities\n",
    "        )\n",
    "        return data\n",
    "        return to_undirected(data)  # Ensure the graph is undirected\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HistoricalRecord:\n",
    "    relation_id: int\n",
    "    other_entity_id: int\n",
    "    timestamp: int\n",
    "\n",
    "\n",
    "class EntityHistoryCache:\n",
    "    def __init__(self, history_length: int) -> None:\n",
    "        self.history_length = history_length\n",
    "\n",
    "        self.cache: Dict[int, List[HistoricalRecord]] = {}  # entity_id -> history[]\n",
    "        self.timestamps: Dict[int, List[int]] = {}  # entity_id -> timestamp[]\n",
    "\n",
    "        self.current_timestamp = 0\n",
    "\n",
    "    def add_to_history(\n",
    "        self, entity_id: int, relation_id: int, other_entity_id: int, timestamp: int\n",
    "    ) -> None:\n",
    "        if entity_id not in self.cache:\n",
    "            self.cache[entity_id] = []\n",
    "            self.timestamps[entity_id] = None\n",
    "\n",
    "        self.cache[entity_id].append(\n",
    "            HistoricalRecord(relation_id, other_entity_id, timestamp)\n",
    "        )\n",
    "        self.timestamps[entity_id] = timestamp\n",
    "\n",
    "        # Remove old history entries\n",
    "        if len(self.cache[entity_id]) > self.history_length:\n",
    "            self.cache[entity_id].pop(0)\n",
    "\n",
    "    def increment_timestamp(self) -> None:\n",
    "        self.current_timestamp += 1\n",
    "\n",
    "        # Update timestamps\n",
    "        for entity_id in self.cache.keys():\n",
    "            if self.timestamps[entity_id] is None:\n",
    "                continue\n",
    "\n",
    "            if self.timestamps[entity_id] >= self.current_timestamp:\n",
    "                while \n",
    "\n",
    "    def get_history(self, entity_id: int) -> Tuple[List[HistoricalRecord], int]:\n",
    "        return self.cache.get(entity_id, []), self.timestamps.get(entity_id, 0)\n",
    "\n",
    "\n",
    "class HistoryCache:\n",
    "    \"\"\"\n",
    "    The HistoryCache is responsible for maintaining and managing the historical interactions\n",
    "    of entities (either source or objects) in the graph, up to a specific length (history length).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_entities, history_length):\n",
    "        self.num_entities = num_entities\n",
    "        self.history_length = history_length\n",
    "        self.histories = [[] for _ in range(num_entities)]\n",
    "        self.timestamps = [[] for _ in range(num_entities)]\n",
    "        self.cache = [[] for _ in range(num_entities)]\n",
    "        self.cache_timestamps = [None for _ in range(num_entities)]\n",
    "\n",
    "    def update_history(self):\n",
    "        for entity_id in range(self.num_entities):\n",
    "            # Remove old history entries\n",
    "            while len(self.histories[entity_id]) > self.history_length:\n",
    "                self.histories[entity_id].pop(0)\n",
    "                self.timestamps[entity_id].pop(0)\n",
    "\n",
    "            if len(self.cache[entity_id]) > 0:\n",
    "                if len(self.histories[entity_id]) >= self.history_length:\n",
    "                    self.histories[entity_id].pop(0)\n",
    "                    self.timestamps[entity_id].pop(0)\n",
    "\n",
    "                self.histories[entity_id].append(self.cache[entity_id].copy())\n",
    "                self.timestamps[entity_id].append(self.cache_timestamps[entity_id])\n",
    "                self.cache[entity_id] = []\n",
    "                self.cache_timestamps[entity_id] = None\n",
    "\n",
    "    def add_to_cache(self, entity_id, relation_id, other_entity_id, timestamp):\n",
    "        if len(self.cache[entity_id]) == 0:\n",
    "            self.cache[entity_id] = np.array([[relation_id, other_entity_id]])\n",
    "        else:\n",
    "            self.cache[entity_id] = np.concatenate(\n",
    "                (self.cache[entity_id], [[relation_id, other_entity_id]]), axis=0\n",
    "            )\n",
    "        self.cache_timestamps[entity_id] = timestamp\n",
    "\n",
    "    def get_history(self, entity_id):\n",
    "        return self.histories[entity_id], self.timestamps[entity_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT_FILENAME = \"stat.txt\"\n",
    "TRAIN_FILENAME = \"train.txt\"\n",
    "\n",
    "train_path = os.path.join(IN_PATH, TRAIN_FILENAME)\n",
    "stat_path = os.path.join(IN_PATH, STAT_FILENAME)\n",
    "\n",
    "# Load the data\n",
    "dataloader = DataLoader()\n",
    "quadruples, times = dataloader.load_quadruples(train_path)\n",
    "num_entities, num_relations = dataloader.get_total_number(stat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/211\n",
      "Processing 100/211\n",
      "Processing 200/211\n"
     ]
    }
   ],
   "source": [
    "# Process the data\n",
    "graph_generator = GraphGenerator(num_entities=num_entities, num_relations=num_relations)\n",
    "history_cache = HistoryCache(num_entities=num_entities, history_length=10)\n",
    "\n",
    "\n",
    "# Create Temporal snapshots\n",
    "def _create_temporal_snapshots(\n",
    "    quadruples: List[Quadruple], times: List[int], graph_generator: GraphGenerator\n",
    ") -> Dict[int, Data]:\n",
    "    graph_dict = {}\n",
    "    for idx, t in enumerate(times):\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Processing {idx}/{len(times)}\")\n",
    "        data = graph_generator.get_data_for_time_step(quadruples, t)\n",
    "\n",
    "        graph = graph_generator.generate_graph(data)\n",
    "        graph_dict[t] = graph\n",
    "    return graph_dict\n",
    "\n",
    "\n",
    "temporal_snapshot_graphs = _create_temporal_snapshots(\n",
    "    quadruples, times, graph_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New timestep: 0, at index 0\n",
      "New timestep: 1, at index 1513\n",
      "New timestep: 2, at index 3026\n",
      "New timestep: 3, at index 4538\n",
      "New timestep: 4, at index 6055\n",
      "New timestep: 5, at index 8146\n",
      "New timestep: 6, at index 10239\n",
      "New timestep: 7, at index 12333\n",
      "New timestep: 8, at index 14433\n",
      "New timestep: 9, at index 16524\n",
      "New timestep: 10, at index 18620\n",
      "New timestep: 11, at index 20718\n",
      "New timestep: 12, at index 22822\n",
      "New timestep: 13, at index 24914\n",
      "New timestep: 14, at index 27010\n",
      "New timestep: 15, at index 29106\n",
      "New timestep: 16, at index 31211\n",
      "New timestep: 17, at index 33321\n",
      "New timestep: 18, at index 35429\n",
      "New timestep: 19, at index 37561\n",
      "New timestep: 20, at index 39689\n",
      "New timestep: 21, at index 41813\n",
      "New timestep: 22, at index 43947\n",
      "New timestep: 23, at index 46078\n",
      "New timestep: 24, at index 48210\n",
      "New timestep: 25, at index 50342\n",
      "New timestep: 26, at index 52474\n",
      "New timestep: 27, at index 54609\n",
      "New timestep: 28, at index 56747\n",
      "New timestep: 29, at index 58882\n",
      "New timestep: 30, at index 61040\n",
      "New timestep: 31, at index 63186\n",
      "New timestep: 32, at index 65332\n",
      "New timestep: 33, at index 67478\n",
      "New timestep: 34, at index 69630\n",
      "New timestep: 35, at index 71780\n",
      "New timestep: 36, at index 73931\n",
      "New timestep: 37, at index 76083\n",
      "New timestep: 38, at index 78238\n",
      "New timestep: 39, at index 80403\n",
      "New timestep: 40, at index 82570\n",
      "New timestep: 41, at index 84733\n",
      "New timestep: 42, at index 86893\n",
      "New timestep: 43, at index 89059\n",
      "New timestep: 44, at index 91229\n",
      "New timestep: 45, at index 93398\n",
      "New timestep: 46, at index 95567\n",
      "New timestep: 47, at index 97743\n",
      "New timestep: 48, at index 99920\n",
      "New timestep: 49, at index 102102\n",
      "New timestep: 50, at index 104280\n",
      "New timestep: 51, at index 106460\n",
      "New timestep: 52, at index 108640\n",
      "New timestep: 53, at index 110822\n",
      "New timestep: 54, at index 113002\n",
      "New timestep: 55, at index 115191\n",
      "New timestep: 56, at index 117382\n",
      "New timestep: 57, at index 119569\n",
      "New timestep: 58, at index 121759\n",
      "New timestep: 59, at index 123950\n",
      "New timestep: 60, at index 126140\n",
      "New timestep: 61, at index 128344\n",
      "New timestep: 62, at index 130548\n",
      "New timestep: 63, at index 132755\n",
      "New timestep: 64, at index 134969\n",
      "New timestep: 65, at index 137177\n",
      "New timestep: 66, at index 139392\n",
      "New timestep: 67, at index 141615\n",
      "New timestep: 68, at index 143833\n",
      "New timestep: 69, at index 146061\n",
      "New timestep: 70, at index 148288\n",
      "New timestep: 71, at index 150516\n",
      "New timestep: 72, at index 152743\n",
      "New timestep: 73, at index 154970\n",
      "New timestep: 74, at index 157206\n",
      "New timestep: 75, at index 159439\n",
      "New timestep: 76, at index 161687\n",
      "New timestep: 77, at index 163933\n",
      "New timestep: 78, at index 166177\n",
      "New timestep: 79, at index 168419\n",
      "New timestep: 80, at index 170668\n",
      "New timestep: 81, at index 172934\n",
      "New timestep: 82, at index 175216\n",
      "New timestep: 83, at index 177476\n",
      "New timestep: 84, at index 179740\n",
      "New timestep: 85, at index 182009\n",
      "New timestep: 86, at index 184709\n",
      "New timestep: 87, at index 186946\n",
      "New timestep: 88, at index 189194\n",
      "New timestep: 89, at index 191442\n",
      "New timestep: 90, at index 193690\n",
      "New timestep: 91, at index 195947\n",
      "New timestep: 92, at index 198208\n",
      "New timestep: 93, at index 200476\n",
      "New timestep: 94, at index 202740\n",
      "New timestep: 95, at index 205006\n",
      "New timestep: 96, at index 207273\n",
      "New timestep: 97, at index 209538\n",
      "New timestep: 98, at index 211807\n",
      "New timestep: 99, at index 214084\n",
      "New timestep: 100, at index 216383\n",
      "New timestep: 101, at index 218688\n",
      "New timestep: 102, at index 220987\n",
      "New timestep: 103, at index 223290\n",
      "New timestep: 104, at index 225593\n",
      "New timestep: 105, at index 227895\n",
      "New timestep: 106, at index 230204\n",
      "New timestep: 107, at index 232520\n",
      "New timestep: 108, at index 234839\n",
      "New timestep: 109, at index 237158\n",
      "New timestep: 110, at index 239484\n",
      "New timestep: 111, at index 241802\n",
      "New timestep: 112, at index 244132\n",
      "New timestep: 113, at index 246471\n",
      "New timestep: 114, at index 248809\n",
      "New timestep: 115, at index 251158\n",
      "New timestep: 116, at index 253525\n",
      "New timestep: 117, at index 255900\n",
      "New timestep: 118, at index 258281\n",
      "New timestep: 119, at index 260671\n",
      "New timestep: 120, at index 263049\n",
      "New timestep: 121, at index 265440\n",
      "New timestep: 122, at index 267832\n",
      "New timestep: 123, at index 270229\n",
      "New timestep: 124, at index 272634\n",
      "New timestep: 125, at index 275051\n",
      "New timestep: 126, at index 277452\n",
      "New timestep: 127, at index 279867\n",
      "New timestep: 128, at index 282281\n",
      "New timestep: 129, at index 284701\n",
      "New timestep: 130, at index 287123\n",
      "New timestep: 131, at index 289538\n",
      "New timestep: 132, at index 292020\n",
      "New timestep: 133, at index 294488\n",
      "New timestep: 134, at index 296940\n",
      "New timestep: 135, at index 299719\n",
      "New timestep: 136, at index 302216\n",
      "New timestep: 137, at index 304762\n",
      "New timestep: 138, at index 307265\n",
      "New timestep: 139, at index 309776\n",
      "New timestep: 140, at index 312301\n",
      "New timestep: 141, at index 314818\n",
      "New timestep: 142, at index 317361\n",
      "New timestep: 143, at index 319924\n",
      "New timestep: 144, at index 322489\n",
      "New timestep: 145, at index 325085\n",
      "New timestep: 146, at index 327666\n",
      "New timestep: 147, at index 330261\n",
      "New timestep: 148, at index 332883\n",
      "New timestep: 149, at index 335496\n",
      "New timestep: 150, at index 338110\n",
      "New timestep: 151, at index 340723\n",
      "New timestep: 152, at index 343336\n",
      "New timestep: 153, at index 345957\n",
      "New timestep: 154, at index 348597\n",
      "New timestep: 155, at index 351236\n",
      "New timestep: 156, at index 353869\n",
      "New timestep: 157, at index 356498\n",
      "New timestep: 158, at index 359153\n",
      "New timestep: 159, at index 361839\n",
      "New timestep: 160, at index 364582\n",
      "New timestep: 161, at index 367309\n",
      "New timestep: 162, at index 370024\n",
      "New timestep: 163, at index 372751\n",
      "New timestep: 164, at index 375556\n",
      "New timestep: 165, at index 378375\n",
      "New timestep: 166, at index 381202\n",
      "New timestep: 167, at index 384025\n",
      "New timestep: 168, at index 386860\n",
      "New timestep: 169, at index 389697\n",
      "New timestep: 170, at index 392544\n",
      "New timestep: 171, at index 395409\n",
      "New timestep: 172, at index 398315\n",
      "New timestep: 173, at index 401239\n",
      "New timestep: 174, at index 404188\n",
      "New timestep: 175, at index 407180\n",
      "New timestep: 176, at index 410190\n",
      "New timestep: 177, at index 413235\n",
      "New timestep: 178, at index 416306\n",
      "New timestep: 179, at index 419397\n",
      "New timestep: 180, at index 422535\n",
      "New timestep: 181, at index 425715\n",
      "New timestep: 182, at index 428925\n",
      "New timestep: 183, at index 432291\n",
      "New timestep: 184, at index 435541\n",
      "New timestep: 185, at index 438819\n",
      "New timestep: 186, at index 442098\n",
      "New timestep: 187, at index 445420\n",
      "New timestep: 188, at index 448767\n",
      "New timestep: 189, at index 452180\n",
      "New timestep: 190, at index 455587\n",
      "New timestep: 191, at index 459033\n",
      "New timestep: 192, at index 462515\n",
      "New timestep: 193, at index 466020\n",
      "New timestep: 194, at index 469554\n",
      "New timestep: 195, at index 473152\n",
      "New timestep: 196, at index 476749\n",
      "New timestep: 197, at index 480403\n",
      "New timestep: 198, at index 484100\n",
      "New timestep: 199, at index 487835\n",
      "New timestep: 200, at index 491651\n",
      "New timestep: 201, at index 495533\n",
      "New timestep: 202, at index 499494\n",
      "New timestep: 203, at index 503539\n",
      "New timestep: 204, at index 507629\n",
      "New timestep: 205, at index 511848\n",
      "New timestep: 206, at index 516150\n",
      "New timestep: 207, at index 520502\n",
      "New timestep: 208, at index 525003\n",
      "New timestep: 209, at index 529617\n",
      "New timestep: 210, at index 534372\n"
     ]
    }
   ],
   "source": [
    "def _create_historical_context(\n",
    "    quadruples: List[Quadruple], source_cache: HistoryCache, object_cache: HistoryCache\n",
    "):\n",
    "    num_quadruples = len(quadruples)\n",
    "\n",
    "    # Sort quadruples by timestamp\n",
    "    quadruples = sorted(quadruples, key=lambda x: x.timestamp)\n",
    "\n",
    "    # Initialize history data containers\n",
    "    s_history_data = [[] for _ in range(num_quadruples)]\n",
    "    s_history_data_t = [[] for _ in range(num_quadruples)]\n",
    "    o_history_data = [[] for _ in range(num_quadruples)]\n",
    "    o_history_data_t = [[] for _ in range(num_quadruples)]\n",
    "\n",
    "    latest_t = -1\n",
    "\n",
    "    for i, quadruple in enumerate(quadruples):\n",
    "        source_id = quadruple.source_id\n",
    "        relation_id = quadruple.relation_id\n",
    "        object_id = quadruple.object_id\n",
    "        timestep = quadruple.timestamp\n",
    "\n",
    "        if latest_t != timestep:\n",
    "            print(f\"New timestep: {timestep}, at index {i}\")\n",
    "            source_cache.update_history(timestep)\n",
    "            object_cache.update_history(timestep)\n",
    "            latest_t = timestep\n",
    "\n",
    "        source_cache.add_to_cache(source_id, relation_id, object_id, timestep)\n",
    "        object_cache.add_to_cache(object_id, relation_id, source_id, timestep)\n",
    "\n",
    "        s_history_data[i], s_history_data_t[i] = source_cache.get_history(source_id)\n",
    "        o_history_data[i], o_history_data_t[i] = object_cache.get_history(object_id)\n",
    "\n",
    "    return s_history_data, s_history_data_t, o_history_data, o_history_data_t\n",
    "\n",
    "\n",
    "source_cache = HistoryCache(num_entities=num_entities, history_length=10)\n",
    "object_cache = HistoryCache(num_entities=num_entities, history_length=10)\n",
    "\n",
    "s_history_data, s_history_data_t, o_history_data, o_history_data_t = (\n",
    "    _create_historical_context(quadruples, source_cache, object_cache)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
